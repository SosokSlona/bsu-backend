import pdfplumber
import re
import io
from typing import List, Dict
from models import ParsedScheduleResponse, DaySchedule, LessonItem

# --- –†–ï–ì–£–õ–Ø–†–ö–ò ---
TIME_PATTERN = re.compile(r'(\d{1,2}[:.]\d{2})')
# –ò—â–µ–º –§–∞–º–∏–ª–∏—é –∏ –ò–Ω–∏—Ü–∏–∞–ª—ã. –£—á–∏—Ç—ã–≤–∞–µ–º:
# - –î–≤–æ–π–Ω—ã–µ —Ñ–∞–º–∏–ª–∏–∏ (–ö—É–∑—å–º–∏–Ω–∞-–ú–∞–º–µ–¥–æ–≤–∞)
# - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ (–ò–≤–∞–Ω–æ–≤–ò.–ò.)
# - –ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ (–°–∞–º–µ—Ç –ê–∑–∞–ø) - 2 —Å–ª–æ–≤–∞ —Å –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã
TEACHER_PATTERN = re.compile(r'([A-–Ø–Å][–∞-—è—ë]+(?:-[A-–Ø–Å][–∞-—è—ë]+)?\s+(?:[A-–Ø–Å]\.\s?[A-–Ø–Å]\.|[A-–Ø–Å][–∞-—è—ë]+)|[A-–Ø–Å][–∞-—è—ë]+[A-–Ø–Å]\.[A-–Ø–Å]\.)')
TYPE_PATTERN = re.compile(r'\((–ª–µ–∫|–ø—Ä–∞–∫|—Å–µ–º|–ª–∞–±|–∫c—Ä|–∑–∞—á–µ—Ç|—ç–∫–∑.*?|—Ñ|—Å–µ–º–∏–Ω–∞—Ä)\)', re.IGNORECASE)
ROOM_PATTERN = re.compile(r'\b(\d{3,4}[–∞-—è]?|—Å/–∫|—Å/–∑|–∞—É–¥\.?)\b', re.IGNORECASE)

def parse_schedule_pdf(pdf_bytes: bytes, course: int) -> ParsedScheduleResponse:
    print(f"üìê [TIME-FIRST] Starting. Size: {len(pdf_bytes)}")
    schedule_by_group: Dict[str, Dict[str, List[LessonItem]]] = {}
    
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        start_page = max(0, (course - 1) * 2)
        pages = pdf.pages[start_page : start_page + 2]
        
        for page_num, page in enumerate(pages):
            print(f"üìÑ Analyzing Page {page_num + 1}...")
            words = page.extract_words(x_tolerance=2, y_tolerance=2, keep_blank_chars=True)
            
            # --- –®–ê–ì 1: –ù–ê–•–û–î–ò–ú –í–†–ï–ú–Ø (–û–ü–û–†–ù–ê–Ø –û–°–¨) ---
            time_words = []
            for w in words:
                if TIME_PATTERN.search(w['text']):
                    # –í–∞–ª–∏–¥–∞—Ü–∏—è: –≤—Ä–µ–º—è –æ–±—ã—á–Ω–æ —Å–ª–µ–≤–∞ (x < 200)
                    if float(w['x0']) < 200: 
                        time_words.append(w)
            
            if not time_words:
                print("‚ö†Ô∏è No time slots found on page (Is it a text PDF?). Skipping.")
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —Ç–∞–±–ª–∏—Ü—ã
            # –í–µ—Ä—Ö —Ç–∞–±–ª–∏—Ü—ã - —ç—Ç–æ Y –ø–µ—Ä–≤–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –º–∏–Ω—É—Å –æ—Ç—Å—Ç—É–ø
            min_time_y = min([w['top'] for w in time_words])
            # –ì—Ä–∞–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏ —Å–ø—Ä–∞–≤–∞
            max_time_x = max([w['x1'] for w in time_words])
            
            print(f"   ‚è∞ Header Boundary found at Y={min_time_y:.1f}. Time Column ends at X={max_time_x:.1f}")

            # --- –®–ê–ì 2: –°–ö–ê–ù–ò–†–£–ï–ú –®–ê–ü–ö–£ (–ó–æ–Ω–∞ –≤—ã—à–µ min_time_y) ---
            # –ò—â–µ–º –≥—Ä—É–ø–ø—ã –ø—Ä–∞–≤–µ–µ –≤—Ä–µ–º–µ–Ω–∏
            header_words = [w for w in words if w['top'] < min_time_y and w['x0'] > max_time_x]
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ
            header_words.sort(key=lambda w: w['x0'])
            
            # –î–ï–ë–ê–ì: –ß—Ç–æ –º—ã –≤–∏–¥–∏–º –≤ —à–∞–ø–∫–µ?
            header_text_debug = " ".join([w['text'] for w in header_words])
            print(f"   üßê Header Text Scan: '{header_text_debug}'")

            group_anchors = []
            
            for i, w in enumerate(header_words):
                txt = w['text'].lower()
                # 1. –Ø–≤–Ω–æ–µ —Å–ª–æ–≤–æ "–ì—Ä—É–ø–ø–∞"
                if "–≥—Ä—É–ø" in txt:
                    # –ò—â–µ–º —Ü–∏—Ñ—Ä—É —Ä—è–¥–æ–º (–≤ —ç—Ç–æ–º —Å–ª–æ–≤–µ –∏–ª–∏ —Å–ª–µ–¥—É—é—â–µ–º)
                    g_num = ""
                    # "–ì—Ä—É–ø–ø–∞13"
                    num_in_word = re.findall(r'\d+', txt)
                    if num_in_word:
                        g_num = num_in_word[0]
                    # "–ì—Ä—É–ø–ø–∞" "13" (—Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ)
                    elif i + 1 < len(header_words):
                        next_w = header_words[i+1]
                        if next_w['text'].isdigit():
                            g_num = next_w['text']
                    
                    if g_num:
                        center_x = (w['x0'] + w['x1']) / 2
                        group_anchors.append({'name': g_num, 'center': center_x})
                
                # 2. –ü—Ä–æ—Å—Ç–æ —Ü–∏—Ñ—Ä–∞ (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –µ—Å–ª–∏ "–ì—Ä—É–ø–ø–∞" –Ω–µ –ø—Ä–æ—á–∏—Ç–∞–ª–∞—Å—å)
                # –ù–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∞ "–ø–æ—Ö–æ–∂–∞" –Ω–∞ –≥—Ä—É–ø–ø—É (2 —Ü–∏—Ñ—Ä—ã) –∏ –º—ã –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏ –µ—ë —á–µ—Ä–µ–∑ —Å–ª–æ–≤–æ "–ì—Ä—É–ø–ø–∞"
                elif w['text'].isdigit() and len(w['text']) == 2:
                     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥–æ–±–∞–≤–∏–ª–∏ –ª–∏ –º—ã –µ—ë —É–∂–µ
                     already_found = any(g['name'] == w['text'] for g in group_anchors)
                     if not already_found:
                         # –•–∞–∫: —Å—á–∏—Ç–∞–µ–º –≥—Ä—É–ø–ø–æ–π, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –≥–æ–¥ (20, 21...)
                         # –î–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –ª—É—á—à–µ –ø–æ–ª–∞–≥–∞—Ç—å—Å—è –Ω–∞ —Å–ª–æ–≤–æ "–ì—Ä—É–ø–ø–∞", –Ω–æ –ø–æ–∫–∞ —Ç–∞–∫
                         pass 

            if not group_anchors:
                print("‚ö†Ô∏è Groups not found in header. Trying brute-force search for 2-digit numbers...")
                # –§–æ–ª–±—ç–∫: –∏—â–µ–º –ª—é–±—ã–µ 2-–∑–Ω–∞—á–Ω—ã–µ —á–∏—Å–ª–∞ –≤ —à–∞–ø–∫–µ
                for w in header_words:
                    if w['text'].isdigit() and len(w['text']) == 2:
                         # –ò—Å–∫–ª—é—á–∞–µ–º –≥–æ–¥–∞ —Ç–∏–ø–∞ 20, 21 –µ—Å–ª–∏ –æ–Ω–∏ –≤ –¥–∞—Ç–µ, –Ω–æ —Ç—É—Ç —Å–ª–æ–∂–Ω–æ
                         group_anchors.append({'name': w['text'], 'center': (w['x0'] + w['x1'])/2})

            if not group_anchors:
                print("‚ùå Fatal: No groups detected. Skipping page.")
                continue

            # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã (—É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏, –µ—Å–ª–∏ "–ì—Ä—É–ø–ø–∞" –∏ "13" –æ–±–∞ —Å—Ä–∞–±–æ—Ç–∞–ª–∏)
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ X
            group_anchors.sort(key=lambda g: g['center'])
            unique_groups = []
            if group_anchors:
                unique_groups.append(group_anchors[0])
                for g in group_anchors[1:]:
                    # –ï—Å–ª–∏ —Ü–µ–Ω—Ç—Ä –¥–∞–ª–µ–∫–æ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ (> 50px), —ç—Ç–æ –Ω–æ–≤–∞—è –≥—Ä—É–ø–ø–∞
                    if g['center'] - unique_groups[-1]['center'] > 50:
                        unique_groups.append(g)
            
            group_anchors = unique_groups
            print(f"   üèõÔ∏è Groups Located: {[g['name'] for g in group_anchors]}")

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏
            columns = []
            for i, g in enumerate(group_anchors):
                # –õ–µ–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞
                left = (group_anchors[i-1]['center'] + g['center']) / 2 if i > 0 else max_time_x
                # –ü—Ä–∞–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞
                right = (g['center'] + group_anchors[i+1]['center']) / 2 if i < len(group_anchors) - 1 else page.width
                
                columns.append({'name': g['name'], 'x0': left, 'x1': right})

            # --- –®–ê–ì 3: –°–¢–†–û–ò–ú –°–ï–¢–ö–£ –í–†–ï–ú–ï–ù–ò ---
            rows = []
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–ª–æ–≤–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤ —Å—Ç—Ä–æ–∫–∏ (–ø–æ Y)
            time_words.sort(key=lambda w: w['top'])
            current_row_words = [time_words[0]]
            
            for w in time_words[1:]:
                if abs(w['top'] - current_row_words[-1]['top']) < 10:
                    current_row_words.append(w)
                else:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –≤—Ä–µ–º–µ–Ω–∏
                    rows.append(_process_time_row(current_row_words, page.width))
                    current_row_words = [w]
            rows.append(_process_time_row(current_row_words, page.width))
            
            # –£—Ç–æ—á–Ω—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —Å—Ç—Ä–æ–∫ (bottom = top —Å–ª–µ–¥—É—é—â–µ–π)
            for i in range(len(rows) - 1):
                rows[i]['bottom'] = rows[i+1]['top'] - 5
            rows[-1]['bottom'] = page.height # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ –¥–æ –∫–æ–Ω—Ü–∞

            # --- –®–ê–ì 4: –ö–í–ê–ù–¢–û–í–ê–ù–ò–ï (–†–ê–ó–ë–û–† –Ø–ß–ï–ï–ö) ---
            current_day = "–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫"
            
            for row in rows:
                # –ê. –ò—â–µ–º –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏ (—Å–ª–µ–≤–∞ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ –∏–ª–∏ –≤ —Ä–∞–π–æ–Ω–µ –≤—Ä–µ–º–µ–Ω–∏)
                # –ë–µ—Ä–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –≤ —ç—Ç–æ–π –ø–æ–ª–æ—Å–µ Y, –ª–µ–≤–µ–µ –ø–µ—Ä–≤–æ–π –≥—Ä—É–ø–ø—ã
                row_words_all = [w for w in words if w['top'] >= row['top'] and w['bottom'] <= row['bottom']]
                
                for w in row_words_all:
                    if w['x1'] < columns[0]['x0']: # –°–ª–µ–≤–∞ –æ—Ç –¥–∞–Ω–Ω—ã—Ö
                        d_txt = w['text'].lower()
                        for dname in ['–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', '–≤—Ç–æ—Ä–Ω–∏–∫', '—Å—Ä–µ–¥–∞', '—á–µ—Ç–≤–µ—Ä–≥', '–ø—è—Ç–Ω–∏—Ü–∞', '—Å—É–±–±–æ—Ç–∞']:
                            if dname in d_txt:
                                current_day = dname.capitalize()

                # –ë. –†–∞–∑–±–∏—Ä–∞–µ–º —è—á–µ–π–∫–∏ –≥—Ä—É–ø–ø
                for col in columns:
                    cell_words = []
                    for w in row_words_all:
                        w_center = (w['x0'] + w['x1']) / 2
                        w_width = w['x1'] - w['x0']
                        col_width = col['x1'] - col['x0']
                        
                        # 1. –°—Ç—Ä–æ–≥–æ –≤–Ω—É—Ç—Ä–∏
                        if col['x0'] <= w_center < col['x1']:
                            cell_words.append(w)
                        # 2. –õ–µ–∫—Ü–∏—è (–ù–∞–≤–∏—Å–∞–µ—Ç –Ω–∞–¥ –∫–æ–ª–æ–Ω–∫–æ–π)
                        # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç > 50% –∫–æ–ª–æ–Ω–∫–∏
                        elif min(w['x1'], col['x1']) - max(w['x0'], col['x0']) > col_width * 0.5:
                            cell_words.append(w)

                    if not cell_words: continue
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ —Å–æ–±–∏—Ä–∞–µ–º
                    cell_words.sort(key=lambda w: (int(w['top']), w['x0']))
                    text = " ".join([w['text'] for w in cell_words])
                    
                    if len(text) < 3 or "—Å/–∫" in text.lower(): continue
                    
                    lessons = _parse_lesson_text(text)
                    
                    g_key = f"–ì—Ä—É–ø–ø–∞ {col['name']}"
                    if g_key not in schedule_by_group: schedule_by_group[g_key] = {}
                    if current_day not in schedule_by_group[g_key]: schedule_by_group[g_key][current_day] = []
                    
                    for l in lessons:
                        l.time_start = row['start']
                        l.time_end = row['end']
                        # –î—É–±–ª–∏–∫–∞—Ç—ã (–¥–ª—è –ª–µ–∫—Ü–∏–π)
                        is_dup = any(x.subject == l.subject and x.time_start == l.time_start for x in schedule_by_group[g_key][current_day])
                        if not is_dup:
                            schedule_by_group[g_key][current_day].append(l)

    final_output = {}
    for g, d in schedule_by_group.items():
        week = []
        for dn, ls in d.items(): week.append(DaySchedule(day_name=dn, lessons=ls))
        final_output[g] = week
    
    print(f"‚úÖ [DONE] Groups: {list(final_output.keys())}")
    return ParsedScheduleResponse(groups=final_output)

def _process_time_row(words, page_width):
    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≤—Ä–µ–º–µ–Ω–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "8.30" –∏ "-9.50")
    words.sort(key=lambda w: w['x0'])
    text = "".join([w['text'] for w in words])
    
    # –ò—â–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
    matches = TIME_PATTERN.findall(text)
    start, end = "", ""
    if len(matches) >= 1: start = matches[0].replace('.', ':')
    if len(matches) >= 2: end = matches[1].replace('.', ':')
    
    top = min([w['top'] for w in words]) - 5
    # Bottom –ø–æ–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–π, –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω
    return {'start': start, 'end': end, 'top': top, 'bottom': top + 50}

def _parse_lesson_text(text: str) -> List[LessonItem]:
    # –£–º–Ω—ã–π –ø–∞—Ä—Å–µ—Ä: –≤—ã—Ä–µ–∑–∞–µ–º –∏–∑–≤–µ—Å—Ç–Ω–æ–µ
    orig = text
    text = text.replace('\n', ' ').strip()
    
    # 1. –¢–∏–ø
    l_type = "–ü—Ä–∞–∫"
    tm = TYPE_PATTERN.search(text)
    if tm:
        v = tm.group(1).lower()
        if "–ª–µ–∫" in v: l_type = "–õ–µ–∫—Ü–∏—è"
        elif "—Å–µ–º" in v: l_type = "–°–µ–º–∏–Ω–∞—Ä"
        elif "–ª–∞–±" in v: l_type = "–õ–∞–±–∞"
        text = text.replace(tm.group(0), "")
        
    # 2. –ê—É–¥
    room = ""
    rm = ROOM_PATTERN.search(text)
    if rm:
        room = rm.group(0)
        text = text.replace(room, "")
        
    # 3. –ü—Ä–µ–ø–æ–¥
    teacher = ""
    ts = list(TEACHER_PATTERN.finditer(text))
    if ts:
        t = ts[-1] # –ü–æ—Å–ª–µ–¥–Ω–∏–π (–æ–±—ã—á–Ω–æ –≤ –∫–æ–Ω—Ü–µ)
        teacher = t.group(0).strip()
        text = text.replace(teacher, "")
        
    # 4. –ü—Ä–µ–¥–º–µ—Ç
    subj = text.replace("-", "").strip(" .,")
    if len(subj) < 3:
        if "–∞–Ω–≥–ª" in orig.lower(): subj = "–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–π —è–∑—ã–∫"
        else: subj = "–ó–∞–Ω—è—Ç–∏–µ"
        
    subg = None
    if "–∞–Ω–≥–ª" in orig.lower(): subg = "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π"
    elif "–Ω–µ–º" in orig.lower(): subg = "–ù–µ–º–µ—Ü–∫–∏–π"
    
    return [LessonItem(subject=subj, type=l_type, teacher=teacher, room=room, time_start="", time_end="", subgroup=subg)]