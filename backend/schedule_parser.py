import pdfplumber
import re
import io
from typing import List, Dict, Any
from models import ParsedScheduleResponse, DaySchedule, LessonItem

# --- –ö–û–ù–°–¢–ê–ù–¢–´ ---
# –î–æ–ø—É—Å–∫ –ø–æ Y (–≤ –ø–∏–∫—Å–µ–ª—è—Ö), —á—Ç–æ–±—ã —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ —Ç–µ–∫—Å—Ç –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
Y_TOLERANCE = 5 
# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞, —á—Ç–æ–±—ã —Å—á–∏—Ç–∞—Ç—å –µ–≥–æ "–õ–µ–∫—Ü–∏–µ–π –Ω–∞ –ø–æ—Ç–æ–∫"
LECTURE_WIDTH_THRESHOLD = 150 

# –†–µ–≥—É–ª—è—Ä–∫–∏
TIME_PATTERN = re.compile(r'(\d{1,2}[:.]\d{2})\s*[-‚Äì]\s*(\d{1,2}[:.]\d{2})')
# –ò—â–µ–º "–ì—Ä—É–ø–ø–∞" –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ü–∏—Ñ—Ä—ã, –µ—Å–ª–∏ –æ–Ω–∏ –≤ —à–∞–ø–∫–µ
GROUP_HEADER_PATTERN = re.compile(r'(?:–≥—Ä—É–ø–ø–∞\s*)?(\d{2,3})', re.IGNORECASE)

def parse_schedule_pdf(pdf_bytes: bytes, course: int) -> ParsedScheduleResponse:
    print(f"üìê [GEOMETRY] Starting parsing... Size: {len(pdf_bytes)}")
    schedule_by_group: Dict[str, Dict[str, List[LessonItem]]] = {}
    
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        start_page = max(0, (course - 1) * 2)
        pages = pdf.pages[start_page : start_page + 2]
        
        for page_num, page in enumerate(pages):
            print(f"üìÑ Analyzing Page {page_num + 1} with Geometry...")
            
            # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –í–°–ï —Å–ª–æ–≤–∞ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
            # words = list of dicts: {'text':Str, 'x0':float, 'x1':float, 'top':float, 'bottom':float}
            words = page.extract_words(x_tolerance=2, y_tolerance=2, keep_blank_chars=True)
            
            # 2. –ò—â–µ–º –Ø–ö–û–†–Ø –ì–†–£–ü–ü (–ö–æ—Ä–∏–¥–æ—Ä—ã X)
            # –ò—â–µ–º —Å–ª–æ–≤–∞ "–ì—Ä—É–ø–ø–∞" –∏–ª–∏ –Ω–æ–º–µ—Ä–∞ –≥—Ä—É–ø–ø –≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (top < 150)
            group_columns = [] # [{'name': '17', 'x0': 100, 'x1': 200}, ...]
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–æ–≤–∞ –ø–æ Y, –ø–æ—Ç–æ–º –ø–æ X
            words.sort(key=lambda w: (w['top'], w['x0']))
            
            # –ê–Ω–∞–ª–∏–∑ —à–∞–ø–∫–∏ (–ø–µ—Ä–≤—ã–µ 20% —Å–ª–æ–≤)
            header_words = [w for w in words if w['top'] < page.height * 0.2]
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–ª–æ–≤–æ "–ì—Ä—É–ø–ø–∞" –∏ —Å–ª–µ–¥—É—é—â–∏–µ –∑–∞ –Ω–∏–º —Ü–∏—Ñ—Ä—ã
            for w in header_words:
                txt = w['text'].lower()
                if "–≥—Ä—É–ø–ø–∞" in txt or (w['x0'] > 100 and w['text'].isdigit() and len(w['text'])==2):
                    # –≠—Ç–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –≥—Ä—É–ø–ø–∞
                    # –û—á–∏—â–∞–µ–º –∏–º—è
                    g_name = w['text'].replace("–ì—Ä—É–ø–ø–∞", "").strip()
                    if not g_name: continue # –ü—É—Å—Ç–æ–µ —Å–ª–æ–≤–æ "–ì—Ä—É–ø–ø–∞", –∏—â–µ–º —Ü–∏—Ñ—Ä—É —Ä—è–¥–æ–º (—Å–ª–æ–∂–Ω–æ, —É–ø—Ä–æ—Å—Ç–∏–º)
                    
                    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ü–∏—Ñ—Ä—É "17"
                    if g_name.isdigit():
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –∫–æ—Ä–∏–¥–æ—Ä–∞. 
                        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ –∏–¥–µ—Ç –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ x0 –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –≥—Ä—É–ø–ø—ã
                        group_columns.append({
                            'name': g_name,
                            'x0': float(w['x0']) - 10, # –ß—É—Ç—å —Ä–∞—Å—à–∏—Ä—è–µ–º –≤–ª–µ–≤–æ
                            'x1': float(w['x1']) + 50  # –í—Ä–µ–º–µ–Ω–Ω–∞—è –ø—Ä–∞–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞
                        })

            # –£—Ç–æ—á–Ω—è–µ–º –ø—Ä–∞–≤—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –∫–æ—Ä–∏–¥–æ—Ä–æ–≤
            group_columns.sort(key=lambda g: g['x0'])
            for i in range(len(group_columns) - 1):
                # –ü—Ä–∞–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ —Ç–µ–∫—É—â–µ–π = –ª–µ–≤–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ —Å–ª–µ–¥—É—é—â–µ–π
                group_columns[i]['x1'] = group_columns[i+1]['x0']
            
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –≥—Ä—É–ø–ø–∞ –∏–¥–µ—Ç –¥–æ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if group_columns:
                group_columns[-1]['x1'] = float(page.width)

            print(f"   üèõÔ∏è Found Vertical Corridors: {[g['name'] for g in group_columns]}")
            if not group_columns:
                print("   ‚ö†Ô∏è No groups found via geometry. Skipping page.")
                continue

            # 3. –ò—â–µ–º –£–†–û–í–ù–ò –í–†–ï–ú–ï–ù–ò (–û—Å—å Y)
            time_rows = [] # [{'time': '8.30-9.50', 'top': 100, 'bottom': 120}]
            
            for w in words:
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –≤—Ä–µ–º–µ–Ω–∏ –≤ —Ç–µ–∫—Å—Ç–µ
                if TIME_PATTERN.search(w['text']):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç –ª–∏ —ç—Ç–æ (—Ä—è–¥–æ–º –ø–æ Y)
                    is_duplicate = False
                    for existing in time_rows:
                        if abs(existing['top'] - w['top']) < 10:
                            is_duplicate = True
                            break
                    
                    if not is_duplicate:
                        # –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º—è
                        tm = TIME_PATTERN.search(w['text'])
                        t_str = f"{tm.group(1).replace('.', ':')} - {tm.group(2).replace('.', ':')}"
                        time_rows.append({
                            'time': t_str,
                            'top': float(w['top']),
                            'bottom': float(w['bottom'])
                        })
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑)
            time_rows.sort(key=lambda t: t['top'])
            print(f"   ‚è∞ Found {len(time_rows)} time slots")

            # 4. –ú–ê–¢–†–ò–¶–ê –ü–ï–†–ï–°–ï–ß–ï–ù–ò–ô (Mapping)
            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Å–ª–æ—Ç–∞...
            current_day = "–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫" # –î–µ—Ñ–æ–ª—Ç
            
            for i, t_row in enumerate(time_rows):
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Å–æ—Ç—É —Å—Ç—Ä–æ–∫–∏: –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ (–∏–ª–∏ –¥–æ –∫–æ–Ω—Ü–∞)
                row_top = t_row['top'] - 5
                row_bottom = time_rows[i+1]['top'] - 5 if i < len(time_rows)-1 else page.height
                
                # –ò—â–µ–º –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏ —Å–ª–µ–≤–∞ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ (x < 100) –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–π –≤—ã—Å–æ—Ç—ã
                day_candidates = [w for w in words 
                                  if w['x1'] < group_columns[0]['x0'] 
                                  and w['top'] >= row_top - 20 # –ß—É—Ç—å –≤—ã—à–µ —Å–º–æ—Ç—Ä–∏–º
                                  and w['bottom'] <= row_bottom]
                
                for dc in day_candidates:
                    d_txt = dc['text'].lower()
                    for day_name in ['–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', '–≤—Ç–æ—Ä–Ω–∏–∫', '—Å—Ä–µ–¥–∞', '—á–µ—Ç–≤–µ—Ä–≥', '–ø—è—Ç–Ω–∏—Ü–∞', '—Å—É–±–±–æ—Ç–∞']:
                        if day_name in d_txt:
                            current_day = day_name.capitalize()
                            break

                # 5. –°–ë–û–† –£–†–û–ñ–ê–Ø (–¢–µ–∫—Å—Ç –≤–Ω—É—Ç—Ä–∏ —è—á–µ–µ–∫)
                # –ò—â–µ–º —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ø–∞–¥–∞—é—Ç –≤ —ç—Ç–æ—Ç Y-–¥–∏–∞–ø–∞–∑–æ–Ω
                row_words = [w for w in words if w['top'] >= row_top and w['top'] < row_bottom]
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–æ–≤–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º
                for group in group_columns:
                    # –°–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ø–∞–¥–∞—é—Ç –≤ X-–∫–æ—Ä–∏–¥–æ—Ä —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
                    g_words = []
                    
                    for w in row_words:
                        # –¶–µ–Ω—Ç—Ä —Å–ª–æ–≤–∞
                        w_center = (w['x0'] + w['x1']) / 2
                        w_width = w['x1'] - w['x0']
                        
                        # –õ–æ–≥–∏–∫–∞ 1: –°–ª–æ–≤–æ —Å—Ç—Ä–æ–≥–æ –≤–Ω—É—Ç—Ä–∏ –∫–æ–ª–æ–Ω–∫–∏
                        is_inside = (w_center >= group['x0'] and w_center < group['x1'])
                        
                        # –õ–æ–≥–∏–∫–∞ 2 (–õ–ï–ö–¶–ò–Ø): –°–ª–æ–≤–æ –æ—á–µ–Ω—å —à–∏—Ä–æ–∫–æ–µ –∏ –Ω–∞–∫—Ä—ã–≤–∞–µ—Ç –∫–æ–ª–æ–Ω–∫—É
                        # –ï—Å–ª–∏ —à–∏—Ä–∏–Ω–∞ —Å–ª–æ–≤–∞ > 80% —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ –∏ –æ–Ω–æ –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç –µ—ë
                        is_wide_lecture = False
                        if w_width > (group['x1'] - group['x0']) * 0.8:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –æ—Ç—Ä–µ–∑–∫–æ–≤ [wx0, wx1] –∏ [gx0, gx1]
                            overlap = max(0, min(w['x1'], group['x1']) - max(w['x0'], group['x0']))
                            if overlap > 20: # –ï—Å–ª–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ
                                is_wide_lecture = True
                        
                        if is_inside or is_wide_lecture:
                            g_words.append(w)
                    
                    if not g_words: continue
                    
                    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Å–ª–æ–≤ (—Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ Y, –ø–æ—Ç–æ–º –ø–æ X)
                    g_words.sort(key=lambda w: (w['top'] // 5, w['x0'])) # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º (–¥–æ–ø—É—Å–∫ 5px)
                    
                    full_text = _assemble_text(g_words)
                    
                    # –ï—Å–ª–∏ –º—É—Å–æ—Ä - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    if len(full_text) < 4 or "—Å/–∫" in full_text.lower(): continue
                    
                    # –ü–∞—Ä—Å–∏–º –¥–µ—Ç–∞–ª–∏
                    lessons = _smart_parse_text(full_text)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                    g_key = f"–ì—Ä—É–ø–ø–∞ {group['name']}"
                    if g_key not in schedule_by_group: schedule_by_group[g_key] = {}
                    if current_day not in schedule_by_group[g_key]: schedule_by_group[g_key][current_day] = []
                    
                    for l in lessons:
                        l.time_start = t_row['time'].split(' - ')[0]
                        l.time_end = t_row['time'].split(' - ')[1]
                        schedule_by_group[g_key][current_day].append(l)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞
    final_output = {}
    days_order = ['–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', '–í—Ç–æ—Ä–Ω–∏–∫', '–°—Ä–µ–¥–∞', '–ß–µ—Ç–≤–µ—Ä–≥', '–ü—è—Ç–Ω–∏—Ü–∞', '–°—É–±–±–æ—Ç–∞']
    
    for g_name, days in schedule_by_group.items():
        week = []
        sorted_days = sorted(days.items(), key=lambda x: days_order.index(x[0]) if x[0] in days_order else 9)
        for d_name, lessons in sorted_days:
            week.append(DaySchedule(day_name=d_name, lessons=lessons))
        final_output[g_name] = week

    print(f"‚úÖ [GEOMETRY] Done. Groups: {list(final_output.keys())}")
    return ParsedScheduleResponse(groups=final_output)

def _assemble_text(words: List[Dict]) -> str:
    """–°–æ–±–∏—Ä–∞–µ—Ç —Å–ª–æ–≤–∞ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —É—á–∏—Ç—ã–≤–∞—è –æ—Ç—Å—Ç—É–ø—ã"""
    if not words: return ""
    lines = []
    current_line = [words[0]['text']]
    last_top = words[0]['top']
    
    for w in words[1:]:
        if abs(w['top'] - last_top) > 8: # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ
            lines.append(" ".join(current_line))
            current_line = []
            last_top = w['top']
        current_line.append(w['text'])
    
    lines.append(" ".join(current_line))
    return " ".join(lines)

def _smart_parse_text(text: str) -> List[LessonItem]:
    """
    –£–º–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å—Ç—Ä–æ–∫–∏: [–¢–∏–ø] [–ü—Ä–µ–¥–º–µ—Ç] [–ü—Ä–µ–ø–æ–¥] [–ê—É–¥]
    """
    # 1. –¢–∏–ø –∑–∞–Ω—è—Ç–∏—è
    l_type = "–ü—Ä–∞–∫"
    if "(–ª–µ–∫)" in text.lower() or "–ª–µ–∫." in text.lower(): l_type = "–õ–µ–∫—Ü–∏—è"
    elif "(—Å–µ–º)" in text.lower(): l_type = "–°–µ–º–∏–Ω–∞—Ä"
    elif "(–ª–∞–±)" in text.lower(): l_type = "–õ–∞–±–∞"
    
    # 2. –ê—É–¥–∏—Ç–æ—Ä–∏—è (—Ü–∏—Ñ—Ä—ã –≤ –∫–æ–Ω—Ü–µ –∏–ª–∏ —Å/–∫)
    room = ""
    # –ò—â–µ–º 3-4 —Ü–∏—Ñ—Ä—ã, –≤–æ–∑–º–æ–∂–Ω–æ —Å –±—É–∫–≤–æ–π, —Å—Ç–æ—è—â–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ
    room_match = re.search(r'\b(\d{3,4}[–∞-—è]?|—Å/–∫)\b', text, re.IGNORECASE)
    if room_match:
        room = room_match.group(1)
        text = text.replace(room, "") # –í—ã—Ä–µ–∑–∞–µ–º
    
    # 3. –ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å (–§–∞–º–∏–ª–∏—è –ò.–û.)
    teacher = ""
    # –ü–∞—Ç—Ç–µ—Ä–Ω: –ó–∞–≥–ª–∞–≤–Ω–∞—è + —Å—Ç—Ä–æ—á–Ω—ã–µ + –ø—Ä–æ–±–µ–ª + –ó–∞–≥–ª–∞–≤–Ω–∞—è. + –ó–∞–≥–ª–∞–≤–Ω–∞—è.
    teach_match = re.search(r'([A-–Ø–Å][–∞-—è—ë]+\s+[A-–Ø–Å]\.\s?[A-–Ø–Å]\.)', text)
    if teach_match:
        teacher = teach_match.group(1)
        text = text.replace(teacher, "") # –í—ã—Ä–µ–∑–∞–µ–º
        
    # 4. –ü—Ä–µ–¥–º–µ—Ç (–≤—Å—ë —á—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å)
    # –£–¥–∞–ª—è–µ–º –º—É—Å–æ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞
    text = re.sub(r'\(.*?\)', '', text) # –£–¥–∞–ª—è–µ–º –≤—Å–µ –≤ —Å–∫–æ–±–∫–∞—Ö (—Ç–∏–ø—ã)
    text = text.replace("‚Äî", "").replace("-", "").strip()
    subject = re.sub(r'\s+', ' ', text).strip()
    
    if len(subject) < 3: subject = "–ó–∞–Ω—è—Ç–∏–µ"
    
    # –ü–æ–¥–≥—Ä—É–ø–ø–∞
    subgroup = None
    if "–∞–Ω–≥–ª" in subject.lower(): subgroup = "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π"
    elif "–Ω–µ–º" in subject.lower(): subgroup = "–ù–µ–º–µ—Ü–∫–∏–π"
    
    return [LessonItem(
        subject=subject,
        type=l_type,
        teacher=teacher,
        room=room,
        time_start="",
        time_end="",
        subgroup=subgroup
    )]